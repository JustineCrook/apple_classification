{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4ce5652-3e89-4dca-9955-575ff1357469",
   "metadata": {},
   "source": [
    "# Tutorial 1: Data cleaning & visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3671028e-c742-4157-adc8-5e41948a3ade",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a73e94-8655-4d5a-95ad-74fee7e74afe",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f2b17e-2e3d-42fc-83b3-e77742320431",
   "metadata": {},
   "source": [
    "Welcome! This tutorial will show you how to visualize infrared spectroscopy samples from apples using python. From this tutorial you will learn:\n",
    "\n",
    " - how to read data into python from an Excel file\n",
    " - how to use dataframes (pandas package)\n",
    " - how to visualise infrared data\n",
    " - how to perform data standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887a7634-4804-4493-94e5-460be85a26f5",
   "metadata": {},
   "source": [
    "For this tutorial, we have three kinds of apples namely Golden Delicious (`GD`), Granny Smith (`GS`), and Royal Gala (`RG`). The main practical purpose is to use infrared spectrum data to classify between bruised (`B`) sound (`S`) samples.\n",
    "\n",
    "All tutorials will use `GS` data, while participants have to solve the exercises on the other two data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bdef97-937b-4946-9d80-ab6c4d951f90",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ea7ed-ba54-42f7-b0ab-9e626a515f31",
   "metadata": {},
   "source": [
    "First we import some libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "135c88bd-0b44-4ff6-b5d0-34ed3cbad53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 1___\n",
    "\n",
    "import pandas as pd # for importing data into data frame format\n",
    "import seaborn as sns # For drawing useful graphs, such as bar graphs\n",
    "import matplotlib.pyplot as plt # This displays graphs once they have been created\n",
    "import numpy as np # For handling N-DIMENSIONAL ARRAYS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46c6821-785c-4a74-96ac-d93345d28178",
   "metadata": {},
   "source": [
    "The above statements define the prefixes 'pd' and 'sns' which will be used to identify pandas and seaborn functions respectively in the following code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3de0c6-74a8-4dea-8297-e725513c70b4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76013295-d86e-4e9e-8eb5-11992024db4f",
   "metadata": {},
   "source": [
    "### Reading in data  \n",
    "\n",
    "The following code does the following:\n",
    "- reads data from an Excel file\n",
    "- converts the Excel file format into a Pandas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff07fc3-4969-4a71-9013-31217fa7e456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 2___\n",
    "import os \n",
    "df = pd.read_excel(os.path.abspath('../data/Detect-GS.xlsx')) # change the directory as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30064ff1-0a67-421b-be5d-887ec6b32679",
   "metadata": {},
   "source": [
    "Since the excel files lives in a sibling directory `../apple_classification/data` we have to use `os.path.abspath` as it returns the absolute path of current working directory with file name `../data/Detect-GD.xlsx` (see more information at [**this link**](https://www.geeksforgeeks.org/python-os-path-abspath-method-with-example/))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1f8ce8-cee8-464c-9426-29cde199c84d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561423d6-b736-48e6-970a-6e5a9554aa4c",
   "metadata": {},
   "source": [
    "### Examining data \n",
    "\n",
    "First let's take a look at the raw infrared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7000c236-ec3a-47cd-9012-0177349bfe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 3___\n",
    "df.head(5) # shows the first 5 rows of the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0e0e8b-3547-443f-adcd-b4f110aa4027",
   "metadata": {},
   "source": [
    "In the above dataframe, the rows correspond to different apple `GS` samples, while the columns give the values of 2078 variables, which can be explained as follows:\n",
    "- Sample ID\n",
    "- Condition: Bruised (B) or Sound (S) apple\n",
    "- Age (in hours)\n",
    "- Source\n",
    "- 11995.49,...,3999.783: evenly-spaced infrared wave numbers at which intensities are measured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81753e3",
   "metadata": {},
   "source": [
    "We may verify the shape of the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e6eedc-cfb6-4277-9b2d-9049b0ad85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 4___\n",
    "\n",
    "\n",
    "df_shape = df.shape # \"df.shape\" produces a tuple of 2 numbers \n",
    "print(\"the shape of the infrared intensity data is \"+str(df_shape) ) \n",
    "\n",
    "# The individual numbers in the tuple are accessed as follows:\n",
    "print(\"where \" + str(df_shape[0]) +\" is the number of rows, and\")\n",
    "print(str(df_shape[1]) +\" is the number of columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7564f96-cd38-481a-807b-6f0f794d1859",
   "metadata": {},
   "source": [
    "This shows that we are working with high-dimensional data. One of the major tasks is to reduce the data. This can be done manually using feature engineering methods, or automatically using deep learning. However, given the small number of samples we will be focusing on using feature engineering methods, this will be explored more in tutorial 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73fa602-d31f-4d35-82c5-4a4320527294",
   "metadata": {},
   "source": [
    "**Exercise 1:** Display the first 5 elements and the shape of the two other data sets (GD, RG)\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cb2d31-81ef-4052-8263-1eac240d235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ___ code here ____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab62074c-f656-44fb-85fd-584ce76637d2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c187d191-d80e-49dc-a203-fcda81594fab",
   "metadata": {},
   "source": [
    "### Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d1e356-7827-4f70-b81f-2dcab51fc09c",
   "metadata": {},
   "source": [
    "First, let us change the column names, because wavelength values are more comprehensible than wavenumbers. The wavelengths are measured in nanometers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e806021-7e6d-42eb-a170-e9f05cbacb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 5___\n",
    "\n",
    "wavenumbers = np.float_(df.columns[4:])\n",
    "wavelengths = (1/wavenumbers)*10**7 # changing the wavenumber to a wave length\n",
    "print(\"\\n Example: wave number \"+str(wavenumbers[0])+\" in inverse centimeters converts to a wavelength of \"+ str(wavelengths[0]) + \" in nanometers\\n\")\n",
    "\n",
    "df.columns.values[4:] = np.round(wavelengths, 3) # getting just up to 3 decimal numbers\n",
    "# Print first few rows\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b706c0-5085-4d38-a2ce-5f0509e59d4c",
   "metadata": {},
   "source": [
    "Now let's check the frequencies of bruised and sound `GS` apples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871cd7ce-c1fa-4bd0-bfea-848d91bd66fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 6___\n",
    "\n",
    "ax = sns.countplot(x=\"Condition\",data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ed2636-98d0-48fc-b03b-0800d3443407",
   "metadata": {},
   "source": [
    "The graph shows that we have three clases of `GS` apples. However this is a mistake--the small `s` should be changed to `S`, giving two classes (this shows why you should always look at your data!). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a527634f-52ab-48d5-af34-3afcc047c954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 7___\n",
    "\n",
    "df['Condition'] = df['Condition'].str.upper()\n",
    "ax = sns.countplot(x=\"Condition\",data=df)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db499869-40e3-4aa3-8898-0a08b54c4120",
   "metadata": {},
   "source": [
    "Now we're done cleaning the `GS' data.  You can do the rest!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da375a97-8574-4d7e-bfc2-88eceb4c4ffb",
   "metadata": {},
   "source": [
    "**Exercise 2:** Clean the other two datasets\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2973bb-a2c1-4110-b91c-dffe959906c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ___ code here ____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248db40f-cef6-4054-b78f-18308ca5e88a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef5d318-a6e2-43c9-a1b1-f3e72ad24fe4",
   "metadata": {},
   "source": [
    "### Visualising the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dade8f1-36cd-4310-99e0-4d94484605d9",
   "metadata": {},
   "source": [
    "Before we visualise the data, let us separate the dataframe into inputs (X) outputs (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822d8786-37b2-4f97-875e-b825f5d99799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 8___\n",
    "\n",
    "#Inputs (which is the infrared spectral data)\n",
    "X = df.iloc[:, 4: ]\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e15a2-1bd4-478f-848b-de58a24039b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 9___\n",
    "\n",
    "#outputs (Sound and Bruised)\n",
    "Y = df['Condition']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36a5122-af56-4d28-8ddd-29fd511848e2",
   "metadata": {},
   "source": [
    "Visualising all the infrared samples at once will introduce a noisy graph, so let us select randomly about 50 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a9f7b-6d89-4793-afe2-1ea6fbed5c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 10___\n",
    "\n",
    "n = 50\n",
    "randIx  = np.random.choice(len(df), n, replace=False)# Random sample without replacement (avoids duplicates)\n",
    "randIx # those are the indices of randomly selected 50 apple samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f277db7-2517-46de-b637-48dfbb903f29",
   "metadata": {},
   "source": [
    "Now let us visualise the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003a17ab-f1bd-47d9-9d41-5dfa195fb280",
   "metadata": {},
   "source": [
    "**Exercise 3:** Notice that every time you run the cell above a different set of number will appear,\n",
    "Change the code above so that the same set of numbers apppears every time.\n",
    "\n",
    "hint: google search the following key words: `seed`, `numpy`\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd945df1",
   "metadata": {},
   "source": [
    "Finish the display. We convert the dataframes to numpy in order to use the power of numpy fancy indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a1330d-6ecc-4353-9d25-6c5239adde23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 11___\n",
    "\n",
    "# Convert to numpy\n",
    "Xn = X.to_numpy(dtype = 'float')\n",
    "Yn = Y.to_numpy(dtype = 'str')\n",
    "\n",
    "# Select only the ones to display\n",
    "Xn = Xn[randIx,:]\n",
    "Yn = Yn[randIx]\n",
    "\n",
    "# number of samples, number of wavelengths\n",
    "ns,nw = np.shape(Xn)\n",
    "\n",
    "# Select Sound and Bruised samples\n",
    "S_Flag = (Yn =='S')\n",
    "B_Flag = (Yn == 'B')\n",
    "\n",
    "########\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Since we are plotting a 2D numpy array, we will need to be carful with the labels, as we will need just one label to present the type of graph (S, B) \n",
    "\n",
    "plt.plot(np.array(X.columns),np.transpose(Xn[B_Flag,:])[:,:1],'b-', label = \"B\") # just graph the first wavelength of type 'B' with the lables \n",
    "plt.plot(np.array(X.columns),np.transpose(Xn[B_Flag,:])[:,1:],'b-') # graphs the rest of the wavelengths of type 'B' without thier labels \n",
    "    \n",
    "# We make the second curve dashed so that it doesn't cover up the first\n",
    "plt.plot(np.array(X.columns),np.transpose(Xn[S_Flag,:])[:,:1],'r:', label = \"S\")  # just graph the first wavelength of type 'S' without the lables\n",
    "plt.plot(np.array(X.columns),np.transpose(Xn[S_Flag,:])[:,1:],'r:') # graphs the rest of the wavelengths of type 'S' without thier labels\n",
    "\n",
    "plt.title(\"GS apples\", fontweight ='bold', fontsize =12)    \n",
    "plt.xlabel(\"Wavelength (nm)\", fontweight ='bold', fontsize =12)\n",
    "plt.ylabel(\"Absorbance (au)\", fontweight ='bold', fontsize =12)\n",
    "plt.ylim([-.3,2.2])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22472ead-710f-4d06-8ec5-e7e2b79cbe07",
   "metadata": {},
   "source": [
    "**Exercise 4:** Do the visualization for the other 2 datasets\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092301fb-9426-4250-81ff-4bc044a0fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ___ code here ____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee87f3b-ff00-40a9-9ded-21b538a2c61a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d623dce-cabb-4024-b2ad-82e4a1ed4812",
   "metadata": {},
   "source": [
    "### Standard Scaler "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf6b6f9-9e89-48da-896c-92db06383abf",
   "metadata": {},
   "source": [
    "Standardizing features transforms them so that each individual feature has mean 0 and unit variance. This is an often-recommended pre-processing step  when working with many machine learning algorithms. (see more information at [**this link**](https://machinelearningmastery.com/standardscaler-and-minmaxscaler-transforms-in-python/))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c79772-6fba-464e-b6ea-f6263f3dd1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 12___\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X = pd.DataFrame(x_scaled, columns = X.columns)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960d0261-0b99-41f7-87ef-1b46c75bc383",
   "metadata": {},
   "source": [
    "now let us check the data after standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc779632-8694-4198-a7db-0aea23287916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 13___\n",
    "\n",
    "# Convert to numpy\n",
    "Xn = X.to_numpy(dtype = 'float')\n",
    "Yn = Y.to_numpy(dtype = 'str')\n",
    "\n",
    "# Select only the ones to display\n",
    "Xn = Xn[randIx,:]\n",
    "Yn = Yn[randIx]\n",
    "\n",
    "# number of samples, number of wavelengths\n",
    "ns,nw = np.shape(Xn)\n",
    "\n",
    "# Select Sound and Bruised samples\n",
    "S_Flag = (Yn =='S')\n",
    "B_Flag = (Yn == 'B')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.plot(np.array(X.columns),np.transpose(Xn[B_Flag,:])[:,:1],'b-', label = \"B\")\n",
    "plt.plot(np.array(X.columns),np.transpose(Xn[B_Flag,:])[:,1:],'b-')\n",
    "    \n",
    "# We make the second curve dashed so that it doesn't cover up the first\n",
    "plt.plot(np.array(X.columns),np.transpose(Xn[S_Flag,:])[:,:1],'r:', label = \"S\")\n",
    "plt.plot(np.array(X.columns),np.transpose(Xn[S_Flag,:])[:,1:],'r:')\n",
    "\n",
    "plt.title(\"GS apples\", fontweight ='bold', fontsize =12)    \n",
    "plt.xlabel(\"Wavelength (nm)\", fontweight ='bold', fontsize =12)\n",
    "plt.ylabel(\"Absorbance (au)\", fontweight ='bold', fontsize =12)\n",
    "plt.ylim([-3,4])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5425d7ad-e66f-4ff5-b7d0-d068dd7210c9",
   "metadata": {},
   "source": [
    "We notice that there is a better separation for the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8d1f2a-b396-43b5-8b16-a447d482a445",
   "metadata": {},
   "source": [
    "**Exercise 5:** Do the standardization for the other 2 datasets\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f761ce-8a80-41ce-bb5c-126e6c9e7b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ___ code here ____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6c6c84-5fd7-4555-9ae7-ad2d4803cb0d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1566fa9b-36be-4f51-97c2-04ada116b53f",
   "metadata": {},
   "source": [
    "<b><i> Saving data for later use </i></b>\n",
    "\n",
    "We can save the data so that we can call it up again in subsequent notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b5ae3d-37bb-4430-8c17-b2c9d08871a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 14___\n",
    "%store  X\n",
    "%store  Y\n",
    "%store  df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3eaaba-4b1b-4490-ae2d-8a5406fc81c3",
   "metadata": {},
   "source": [
    "`Notice:` this is not a good way of saving the data, especially when working with 3 datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c71f3ec-6710-4d22-9634-0c1e29a2b36a",
   "metadata": {},
   "source": [
    "**Exercise 6:** come up with a better way to save the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5afd385-dd49-415f-ae06-ef99e70ffb79",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter_kernel",
   "language": "python",
   "name": "twitter_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
